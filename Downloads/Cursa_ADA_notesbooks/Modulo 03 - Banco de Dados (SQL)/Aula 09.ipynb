{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "36a701e3",
   "metadata": {},
   "source": [
    "# Databricks\n",
    "## O que é?\n",
    "Desenvolvido pelos mesmos criadores do Apache Spark (framework que discutiremos no futuro), o **Databricks** é uma plataforma de análise de dados unificada para engenharia de dados, machine learning e ciência de dados colaborativa. Se organiza através de workspaces, que são ambientes de software como serviço (SaaS) utilizados para acessar suas funcionalidades e objetos, como notebooks, em pastas e recursos computacionais, como clusters.\n",
    "\n",
    "## Por que utilizar Databricks?\n",
    "### Workspace colaborativo\n",
    "Uma primeira razão para utilizar **Databricks** está em seus workspaces colaborativos, onde usuários diferentes podem compartilhar seus notebooks ou até mesmo trabalhar em um de forma simultânea; experiência similar a do Google Docs ou Word Online.\n",
    "\n",
    "### Para Cientistas, Analistas e Engenheiros de Dados\n",
    "**Databricks** é uma plataforma poderosa que pode ser utilizada de maneira agradável por diferentes profissionais. Ela permite que cientistas de dados manipulem dados e criem modelos para Machine Learning; que analistas usem tabelas estruturadas, arquivos semi-estruturados e se conectem a ferramentas de visualização nativamente, e; que engenheiros de dados extraiam, transformem e carreguem dados em diferentes ambientes.\n",
    "\n",
    "### Pluralidade de Linguagens\n",
    "Os notebooks **Databricks**, similares ao do Jupyter, não se limitam a uma só linguagem de programação: neles é possível utilizar *Python*, *SQL*, *R* e *Scala*. Sendo possível, inclusive, mesclar em um mesmo notebook células em linguagens diferentes e combiná-las posteriormente, como por exemplo criando uma função em Python em uma primeira e a utilizando em um código SQL em uma segunda.\n",
    "\n",
    "A pluralidade de linguagens resolve diversos problemas que times enfrentam ao definir arquitetura e escolher produtos. Se parte dos cientistas for mais familiarizada com Python e outra com R, tudo certo; se alguns engenheiros preferem utilizar Spark em Scala e outros em Python, tudo certo também. Evita-se assim, uma necessidade de adaptar e treinar elementos do time a novas skills.\n",
    "\n",
    "### Multi-cloud\n",
    "**Databricks** é uma ferramenta que pode ser considerada agnóstica por ser multicloud, em outras palavras, se conecta e se complementa muito bem a diferentes plataformas de computação em nuvem, como Amazon Web Services (AWS), Google Cloud Plataform (GCP) e Microsoft Azure. Sendo assim, independente da plataforma escolhida para sediar a arquitetura de uma solução, é possível encaixar produtos do Databricks em uma ou várias etapas.\n",
    "\n",
    "## Versão Community\n",
    "O **Databricks** possui uma versão Community para que estudantes e interessados na plataforma possam degustar e praticar em uma versão gratuita, ainda que com limitações.\n",
    "Outro aspecto importante é que diferente de suas parceiras, AWS Azure e GCP, a versão community é totalmente gratuita. Aquilo que está disponível apenas em versões pagas, simplesmente não funciona. Ou seja, não é preciso inserir um cartão de crédito e fazer um rígido controle dos produtos utilizados para evitar gastos inesperados enquanto está apenas experimentando.\n",
    "\n",
    "### Cluster\n",
    "A tela a seguir é acessada através do menu \"Compute\" à esquerda. Aqui podemos criar um cluster no botão \"Create Cluster\", dando um nome qualquer a ele e mantendo as próximas configurações padrões. Caso o projeto que venha a desenvolver requeira uma versão específica do Spark ou Scala, basta alterar durante a criação. Quanto ao poder computacional (quantidade de nós, memória, etc.), não podemos alterá-lo na versão community.\n",
    "![Compute](https://s3-sa-east-1.amazonaws.com/lcpi/c4f03727-a04d-427c-8d42-99443c98cf7d.png)\n",
    "\n",
    "## Notebook\n",
    ">\"Um **notebook** é uma interface baseada na Web para um documento que contém código executável, visualizações e texto de narração.\" \n",
    "\n",
    "Composto por **células** capazes de executar códigos em diferentes linguagens, é em um notebook que somos capazes de manipular arquivos, criar funções e tabelas, etc.\n",
    "\n",
    "Caso tenha utilizado *Jupyter* anteriormente, saiba que o conceito é o mesmo, assim como a extensão do arquivo .ipynb.\n",
    "\n",
    "Na imagem abaixo temos um exemplo de notebook, em branco, criado em um diretório qualquer no Workspace (no menu à esquerda clicar em workspace e, no menu que se abrir, selecionar o usuário - em um ambiente colaborativo é possível que outros usuários, além do seu, estejam disponíveis. Na área em branco, clicar no botão direito -> Create -> Notebook).\n",
    "Note que, ao lado de seu nome, temos a sua linguagem default (Python), o que quer dizer que por padrão as células esperarão códigos em Python. Abaixo do nome do notebook, selecionamos o cluster em que os códigos serão executados (lembrando que a versão community do **Databricks** nos disponibiliza um gratuitamente). Podemos criar quantas células julgarmos necessárias e, para mudar a linguagem de uma individualmente basta selecionar no menu à direita da célula ou em sua primeira linha colocar '#' seguido do nome da linguagem.\n",
    "\n",
    "Um outro recurso interessante para estudos futuros é acionado no canto superior direito do notebook e diz respeito a versionamento, pois o **Databricks** permite integração com git em versões pagas (Settings -> User Settings -> Git Integration).\n",
    "![Notebook](https://s3-sa-east-1.amazonaws.com/lcpi/76d6485d-92b6-4860-a8a6-257229c4ee8a.png)\n",
    "\n",
    "## DBFS\n",
    "O **DBFS** funciona como uma espécie de HDFS do Hadoop, só que no Databricks. Aqui é possível inserir arquivos e manipulá-los através de comandos similares aos do HDFS. Além disso, diretórios podem ser utilizados para salvar arquivos frutos de processamentos e transformações.\n",
    "\n",
    "Há uma interface visual para navegar pelo DBFS, para ativá-la navegue em: Settings -> Admin Console -> Workspace settings -> DFBS File Browser: Enabled. Ao atualizar a página, ela estará disponível em uma aba no menu \"Data\" à esquerda.\n",
    "\n",
    "Vale ressaltar que o DBFS é uma ferramenta interessante para a versão community e para quem está degustando/estudando a plataforma. Todavia, para arquiteturas profissionais, a própria Databricks recomenda o uso de soluções como Blob Storage da Azure ou S3 da Amazon para armazenamento de dados.\n",
    "\n",
    "### dbutils\n",
    "Databricks Utilities é composto por um conjunto de comandos que podem ser utilizados para trabalhar com armazenamentos de objetos de forma eficiente. Similar ao HDFS DFS do Hadoop (antigo Hadoop fs), está disponível em Notebooks Python, Scala e R.\n",
    "\n",
    "#### Comandos\n",
    "Lista de comandos e orientações:\n",
    "~~~\n",
    "dbutils.fs.help()\n",
    "~~~\n",
    "\n",
    "Criar diretório:\n",
    "~~~\n",
    "dbutils.fs.mkdirs(<caminho até o diretório>)\n",
    "~~~\n",
    "\n",
    "Listar conteúdo de um diretório:\n",
    "~~~\n",
    "dbutils.fs.ls(<caminho até o arquivo/diretório>)\n",
    "~~~\n",
    "\n",
    "Copiar um arquivo ou diretório:\n",
    "~~~\n",
    "dbutils.fs.cp(<caminho até o arquivo/diretório>, <diretório destino>, recursivo (True ou False))\n",
    "~~~\n",
    "\n",
    "Mover um arquivo ou diretório:\n",
    "~~~\n",
    "dbutils.fs.mv(<caminho até o arquivo/diretório>, <diretório destino>, recursivo (True ou False))\n",
    "~~~\n",
    "\n",
    "Deletar um arquivo ou diretório:\n",
    "~~~\n",
    "dbutils.fs.rm(<caminho até o arquivo/diretório>, recursivo (True ou False))\n",
    "~~~\n",
    "\n",
    "Criar arquivo txt:\n",
    "~~~\n",
    "dbutils.fs.put(<caminho até o arquivo>, conteúdo, overwrite (True or False))\n",
    "~~~\n",
    "\n",
    "Retornar os primeiros n bytes de um arquivo:\n",
    "~~~\n",
    "dbutils.fs.ls(<caminho até o arquivo>, quantidade de bytes)\n",
    "~~~\n",
    "\n",
    "### Limitações\n",
    "Algumas limitações que você encontrará ao utilizar a versão **community** do **Databricks** que valem ser citadas:\n",
    "\n",
    "- O cluster disponibilizado, de forma gratuita, é **desligado** após duas horas de inatividade e não pode ser reinicializado. Com isso, embora arquivos no DBFS e notebooks não sejam perdidos, metadados como tabelas criadas serão.\n",
    "- Conexões com serviços de armazenamento (mount), como S3 e Blob Storage, utilizando chaves de segurança não são permitidas.\n",
    "\n",
    "## Indicações e Bibliografia\n",
    "[Databricks Community](https://community.cloud.databricks.com/)\n",
    "\n",
    "[Documentação oficial](https://docs.databricks.com/)\n",
    "\n",
    "[Databricks getting started]()(https://docs.databricks.com/getting-started/quick-start.html)\n",
    "\n",
    "[Databricks na AWS](https://aws.amazon.com/pt/quickstart/architecture/databricks/)\n",
    "\n",
    "[Linguagens compatíveis com Databricks](https://docs.microsoft.com/pt-br/azure/databricks/languages/)\n",
    "\n",
    "[Comandos para manipulação do DBFS](https://docs.databricks.com/dev-tools/databricks-utils.html)\n",
    "\n",
    "[S3 vs HDFS](https://databricks.com/blog/2017/05/31/top-5-reasons-for-choosing-s3-over-hdfs.html)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
